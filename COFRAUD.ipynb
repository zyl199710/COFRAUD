{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "BaMNqGvDif2G",
        "outputId": "b5fec2cd-a309-4c69-99fd-4c9d532a2401"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj3lNtd1Wwj4",
        "outputId": "523dc5a0-9041-42df-bc03-4a1a9871aae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 新段落"
      ],
      "metadata": {
        "id": "06ghJZ4XdTJa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5hHBCBxMXM88",
        "outputId": "d4e9d145-819a-4944-f2e8-74ed61af361e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Othercomputers/我的计算机/COFRAUD\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/Othercomputers/我的计算机/COFRAUD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR0n1T2rg2al",
        "outputId": "b0d03f7d-08fe-4fce-dc43-8d15e36e83b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/Othercomputers/我的计算机/COFRAUD/preprocess_data/alienation.py\", line 136, in <module>\n",
            "    computelocal()\n",
            "  File \"/content/drive/Othercomputers/我的计算机/COFRAUD/preprocess_data/alienation.py\", line 24, in computelocal\n",
            "    G1 = nx.from_scipy_sparse_matrix(sp.coo_matrix(A))\n",
            "AttributeError: module 'networkx' has no attribute 'from_scipy_sparse_matrix'\n"
          ]
        }
      ],
      "source": [
        "!python preprocess_data/alienation.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vMWNT1vgDc8G",
        "outputId": "83cfcabb-41a6-4868-830e-62e5fa890858"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.dgl.ai/wheels/cu121/repo.html\n",
            "Collecting dgl\n",
            "  Downloading https://data.dgl.ai/wheels/cu121/dgl-2.0.0%2Bcu121-cp310-cp310-manylinux1_x86_64.whl (926.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m926.0/926.0 MB\u001b[0m \u001b[31m881.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.11.4)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.66.1)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)\n",
            "Requirement already satisfied: torchdata>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (0.7.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.11.17)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchdata>=0.5.0->dgl) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (1.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchdata>=0.5.0->dgl) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchdata>=0.5.0->dgl) (1.3.0)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-2.0.0+cu121\n",
            "Looking in links: https://data.dgl.ai/wheels-test/repo.html\n",
            "Collecting dglgo\n",
            "  Downloading dglgo-0.0.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.5/63.5 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typer>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (0.9.0)\n",
            "Collecting isort>=5.10.1 (from dglgo)\n",
            "  Downloading isort-5.13.2-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.3/92.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autopep8>=1.6.0 (from dglgo)\n",
            "  Downloading autopep8-2.0.4-py2.py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpydoc>=1.1.0 (from dglgo)\n",
            "  Downloading numpydoc-1.6.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.10.13)\n",
            "Collecting ruamel.yaml>=0.17.20 (from dglgo)\n",
            "  Downloading ruamel.yaml-0.18.5-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.4/116.4 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from dglgo) (6.0.1)\n",
            "Collecting ogb>=1.3.3 (from dglgo)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rdkit-pypi (from dglgo)\n",
            "  Downloading rdkit_pypi-2022.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.4/29.4 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from dglgo) (1.2.2)\n",
            "Collecting pycodestyle>=2.10.0 (from autopep8>=1.6.0->dglgo)\n",
            "  Downloading pycodestyle-2.11.1-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from autopep8>=1.6.0->dglgo) (2.0.1)\n",
            "Requirement already satisfied: sphinx>=5 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (5.0.2)\n",
            "Requirement already satisfied: Jinja2>=2.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (3.1.3)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from numpydoc>=1.1.0->dglgo) (0.9.0)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.29.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (4.66.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.5.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb>=1.3.3->dglgo) (2.0.7)\n",
            "Collecting outdated>=0.2.0 (from ogb>=1.3.3->dglgo)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.0->dglgo) (4.5.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml>=0.17.20->dglgo)\n",
            "  Downloading ruamel.yaml.clib-0.2.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (526 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m526.7/526.7 kB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->dglgo) (3.2.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.4.0->dglgo) (8.1.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from rdkit-pypi->dglgo) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.10->numpydoc>=1.1.0->dglgo) (2.1.3)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (67.7.2)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb>=1.3.3->dglgo)\n",
            "  Downloading littleutils-0.2.2.tar.gz (6.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb>=1.3.3->dglgo) (2.31.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24.0->ogb>=1.3.3->dglgo) (2023.3.post1)\n",
            "Requirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.8)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.6)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.1.10)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.0.7)\n",
            "Requirement already satisfied: Pygments>=2.0 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.16.1)\n",
            "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.18.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (2.14.0)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (0.7.16)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from sphinx>=5->numpydoc>=1.1.0->dglgo) (23.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (3.2.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->ogb>=1.3.3->dglgo) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->outdated>=0.2.0->ogb>=1.3.3->dglgo) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->ogb>=1.3.3->dglgo) (1.3.0)\n",
            "Building wheels for collected packages: littleutils\n",
            "  Building wheel for littleutils (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for littleutils: filename=littleutils-0.2.2-py3-none-any.whl size=7026 sha256=fb6cdcbc90d06413f95106085fb31af303b9b0a3d4684bbfc7146eac9ef9bc0e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/fe/b0/27a9892da57472e538c7452a721a9cf463cc03cf7379889266\n",
            "Successfully built littleutils\n",
            "Installing collected packages: littleutils, ruamel.yaml.clib, rdkit-pypi, pycodestyle, isort, ruamel.yaml, outdated, autopep8, ogb, numpydoc, dglgo\n",
            "Successfully installed autopep8-2.0.4 dglgo-0.0.2 isort-5.13.2 littleutils-0.2.2 numpydoc-1.6.0 ogb-1.3.6 outdated-0.2.2 pycodestyle-2.11.1 rdkit-pypi-2022.9.5 ruamel.yaml-0.18.5 ruamel.yaml.clib-0.2.8\n"
          ]
        }
      ],
      "source": [
        "!pip install  dgl -f https://data.dgl.ai/wheels/cu121/repo.html\n",
        "!pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aS0ai4W2Ic2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8718c8f6-fa3f-4ddc-c966-ace38385ed4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/Othercomputers/我的计算机/COFRAUD\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/Othercomputers/我的计算机/COFRAUD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnyr7mwO6qjQ",
        "outputId": "3c91ead0-66c3-4c2a-8923-d3f799349255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/Othercomputers/我的计算机/COFRAUD/train/train_cofraud_node_classification.py\", line 17, in <module>\n",
            "    from COFRAUD import COFRAUD\n",
            "  File \"/content/drive/Othercomputers/我的计算机/COFRAUD/train/COFRAUD.py\", line 16\n",
            "    residual: bool = True, dataset, norm: bool = False):\n",
            "                           ^^^^^^^\n",
            "SyntaxError: non-default argument follows default argument\n"
          ]
        }
      ],
      "source": [
        "!python train/train_cofraud_node_classification.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q4Vh4Uky6nru",
        "outputId": "eb8da608-aeae-46e1-987e-9e2447e62100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Rethinking-Anomaly-Detection-master\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/Rethinking-Anomaly-Detection-master"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygIY1ZUH6RhF",
        "outputId": "3ceccfb6-da00-4f94-8697-658730b01c93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(dataset='amazon', epoch=200, hid_dim=64, homo=0, order=2, run=1, train_ratio=0.1)\n",
            "Done loading data from cached files.\n",
            "Graph(num_nodes={'user': 11944},\n",
            "      num_edges={('user', 'net_upu', 'user'): 351216, ('user', 'net_usu', 'user'): 7132958, ('user', 'net_uvu', 'user'): 2073474},\n",
            "      metagraph=[('user', 'user', 'net_upu'), ('user', 'user', 'net_usu'), ('user', 'user', 'net_uvu')])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 25])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 64])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64, 192])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([64])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([2, 64])\n",
            "<class 'torch.nn.parameter.Parameter'> torch.Size([2])\n",
            "train/dev/test samples:  863 2566 5210\n",
            "cross entropy weight:  9.524390243902438\n",
            "Test: REC 80.81 PRE 11.91 MF1 37.14 AUC 58.23\n",
            "Epoch 0, loss: 5.2407, val mf1: 0.3704, (best 0.3704)\n",
            "Test: REC 2.02 PRE 4.98 MF1 47.96 AUC 60.86\n",
            "Epoch 1, loss: 55.2365, val mf1: 0.4789, (best 0.4789)\n",
            "Epoch 2, loss: 31.9105, val mf1: 0.1002, (best 0.4789)\n",
            "Test: REC 44.44 PRE 22.16 MF1 58.92 AUC 74.95\n",
            "Epoch 3, loss: 1.6068, val mf1: 0.5831, (best 0.5831)\n",
            "Epoch 4, loss: 5.4756, val mf1: 0.2539, (best 0.5831)\n",
            "Epoch 5, loss: 16.7173, val mf1: 0.4828, (best 0.5831)\n",
            "Epoch 6, loss: 11.4307, val mf1: 0.5168, (best 0.5831)\n",
            "Test: REC 44.85 PRE 23.12 MF1 59.62 AUC 75.53\n",
            "Epoch 7, loss: 2.9714, val mf1: 0.5948, (best 0.5948)\n",
            "Epoch 8, loss: 3.4408, val mf1: 0.3152, (best 0.5948)\n",
            "Epoch 9, loss: 1.8891, val mf1: 0.3621, (best 0.5948)\n",
            "Test: REC 36.16 PRE 39.87 MF1 65.87 AUC 80.35\n",
            "Epoch 10, loss: 1.1933, val mf1: 0.6382, (best 0.6382)\n",
            "Test: REC 58.59 PRE 58.00 MF1 76.94 AUC 86.66\n",
            "Epoch 11, loss: 0.9075, val mf1: 0.7402, (best 0.7402)\n",
            "Epoch 12, loss: 0.8162, val mf1: 0.5730, (best 0.7402)\n",
            "Epoch 13, loss: 0.9216, val mf1: 0.4891, (best 0.7402)\n",
            "Epoch 14, loss: 0.5072, val mf1: 0.7096, (best 0.7402)\n",
            "Test: REC 73.94 PRE 60.70 MF1 81.37 AUC 91.47\n",
            "Epoch 15, loss: 0.5111, val mf1: 0.8121, (best 0.8121)\n",
            "Epoch 16, loss: 0.4434, val mf1: 0.8039, (best 0.8121)\n",
            "Epoch 17, loss: 0.3947, val mf1: 0.7933, (best 0.8121)\n",
            "Epoch 18, loss: 0.3543, val mf1: 0.7792, (best 0.8121)\n",
            "Epoch 19, loss: 0.3258, val mf1: 0.7723, (best 0.8121)\n",
            "Epoch 20, loss: 0.3829, val mf1: 0.6976, (best 0.8121)\n",
            "Epoch 21, loss: 0.2978, val mf1: 0.7767, (best 0.8121)\n",
            "Epoch 22, loss: 0.2853, val mf1: 0.7809, (best 0.8121)\n",
            "Epoch 23, loss: 0.2845, val mf1: 0.7924, (best 0.8121)\n",
            "Epoch 24, loss: 0.2805, val mf1: 0.8059, (best 0.8121)\n",
            "Test: REC 79.39 PRE 61.12 MF1 82.64 AUC 93.45\n",
            "Epoch 25, loss: 0.2673, val mf1: 0.8194, (best 0.8194)\n",
            "Test: REC 78.38 PRE 64.67 MF1 83.72 AUC 93.73\n",
            "Epoch 26, loss: 0.2496, val mf1: 0.8374, (best 0.8374)\n",
            "Epoch 27, loss: 0.2343, val mf1: 0.8351, (best 0.8374)\n",
            "Epoch 28, loss: 0.2280, val mf1: 0.8160, (best 0.8374)\n",
            "Epoch 29, loss: 0.2296, val mf1: 0.7961, (best 0.8374)\n",
            "Epoch 30, loss: 0.2284, val mf1: 0.7839, (best 0.8374)\n",
            "Epoch 31, loss: 0.2135, val mf1: 0.7963, (best 0.8374)\n",
            "Epoch 32, loss: 0.1968, val mf1: 0.8305, (best 0.8374)\n",
            "Test: REC 79.60 PRE 71.90 MF1 86.42 AUC 94.38\n",
            "Epoch 33, loss: 0.1875, val mf1: 0.8631, (best 0.8631)\n",
            "Test: REC 78.79 PRE 74.29 MF1 86.96 AUC 94.61\n",
            "Epoch 34, loss: 0.1861, val mf1: 0.8759, (best 0.8759)\n",
            "Epoch 35, loss: 0.1844, val mf1: 0.8703, (best 0.8759)\n",
            "Epoch 36, loss: 0.1793, val mf1: 0.8603, (best 0.8759)\n",
            "Epoch 37, loss: 0.1746, val mf1: 0.8416, (best 0.8759)\n",
            "Epoch 38, loss: 0.1721, val mf1: 0.8273, (best 0.8759)\n",
            "Epoch 39, loss: 0.1693, val mf1: 0.8238, (best 0.8759)\n",
            "Epoch 40, loss: 0.1638, val mf1: 0.8342, (best 0.8759)\n",
            "Epoch 41, loss: 0.1615, val mf1: 0.8523, (best 0.8759)\n",
            "Epoch 42, loss: 0.1621, val mf1: 0.8635, (best 0.8759)\n",
            "Epoch 43, loss: 0.1581, val mf1: 0.8669, (best 0.8759)\n",
            "Epoch 44, loss: 0.1514, val mf1: 0.8596, (best 0.8759)\n",
            "Epoch 45, loss: 0.1491, val mf1: 0.8447, (best 0.8759)\n",
            "Epoch 46, loss: 0.1492, val mf1: 0.8387, (best 0.8759)\n",
            "Epoch 47, loss: 0.1465, val mf1: 0.8427, (best 0.8759)\n",
            "Epoch 48, loss: 0.1430, val mf1: 0.8559, (best 0.8759)\n",
            "Test: REC 81.01 PRE 70.72 MF1 86.37 AUC 95.19\n",
            "Epoch 49, loss: 0.1413, val mf1: 0.8763, (best 0.8763)\n",
            "Test: REC 80.00 PRE 72.13 MF1 86.59 AUC 95.16\n",
            "Epoch 50, loss: 0.1398, val mf1: 0.8785, (best 0.8785)\n",
            "Epoch 51, loss: 0.1363, val mf1: 0.8729, (best 0.8785)\n",
            "Epoch 52, loss: 0.1332, val mf1: 0.8641, (best 0.8785)\n",
            "Epoch 53, loss: 0.1319, val mf1: 0.8534, (best 0.8785)\n",
            "Epoch 54, loss: 0.1295, val mf1: 0.8549, (best 0.8785)\n",
            "Epoch 55, loss: 0.1260, val mf1: 0.8641, (best 0.8785)\n",
            "Epoch 56, loss: 0.1240, val mf1: 0.8716, (best 0.8785)\n",
            "Epoch 57, loss: 0.1226, val mf1: 0.8750, (best 0.8785)\n",
            "Epoch 58, loss: 0.1204, val mf1: 0.8691, (best 0.8785)\n",
            "Epoch 59, loss: 0.1182, val mf1: 0.8605, (best 0.8785)\n",
            "Epoch 60, loss: 0.1169, val mf1: 0.8518, (best 0.8785)\n",
            "Epoch 61, loss: 0.1153, val mf1: 0.8503, (best 0.8785)\n",
            "Epoch 62, loss: 0.1132, val mf1: 0.8581, (best 0.8785)\n",
            "Epoch 63, loss: 0.1115, val mf1: 0.8646, (best 0.8785)\n",
            "Epoch 64, loss: 0.1101, val mf1: 0.8704, (best 0.8785)\n",
            "Epoch 65, loss: 0.1084, val mf1: 0.8671, (best 0.8785)\n",
            "Epoch 66, loss: 0.1065, val mf1: 0.8589, (best 0.8785)\n",
            "Epoch 67, loss: 0.1049, val mf1: 0.8549, (best 0.8785)\n",
            "Epoch 68, loss: 0.1034, val mf1: 0.8523, (best 0.8785)\n",
            "Epoch 69, loss: 0.1015, val mf1: 0.8557, (best 0.8785)\n",
            "Epoch 70, loss: 0.0998, val mf1: 0.8597, (best 0.8785)\n",
            "Epoch 71, loss: 0.0984, val mf1: 0.8646, (best 0.8785)\n",
            "Epoch 72, loss: 0.0969, val mf1: 0.8638, (best 0.8785)\n",
            "Epoch 73, loss: 0.0952, val mf1: 0.8605, (best 0.8785)\n",
            "Epoch 74, loss: 0.0937, val mf1: 0.8570, (best 0.8785)\n",
            "Epoch 75, loss: 0.0923, val mf1: 0.8546, (best 0.8785)\n",
            "Epoch 76, loss: 0.0908, val mf1: 0.8542, (best 0.8785)\n",
            "Epoch 77, loss: 0.0891, val mf1: 0.8557, (best 0.8785)\n",
            "Epoch 78, loss: 0.0875, val mf1: 0.8581, (best 0.8785)\n",
            "Epoch 79, loss: 0.0861, val mf1: 0.8589, (best 0.8785)\n",
            "Epoch 80, loss: 0.0846, val mf1: 0.8573, (best 0.8785)\n",
            "Epoch 81, loss: 0.0830, val mf1: 0.8534, (best 0.8785)\n",
            "Epoch 82, loss: 0.0815, val mf1: 0.8538, (best 0.8785)\n",
            "Epoch 83, loss: 0.0798, val mf1: 0.8526, (best 0.8785)\n",
            "Epoch 84, loss: 0.0781, val mf1: 0.8542, (best 0.8785)\n",
            "Epoch 85, loss: 0.0766, val mf1: 0.8537, (best 0.8785)\n",
            "Epoch 86, loss: 0.0750, val mf1: 0.8537, (best 0.8785)\n",
            "Epoch 87, loss: 0.0736, val mf1: 0.8549, (best 0.8785)\n",
            "Epoch 88, loss: 0.0719, val mf1: 0.8542, (best 0.8785)\n",
            "Epoch 89, loss: 0.0703, val mf1: 0.8542, (best 0.8785)\n",
            "Epoch 90, loss: 0.0688, val mf1: 0.8562, (best 0.8785)\n",
            "Epoch 91, loss: 0.0673, val mf1: 0.8570, (best 0.8785)\n",
            "Epoch 92, loss: 0.0658, val mf1: 0.8597, (best 0.8785)\n",
            "Epoch 93, loss: 0.0644, val mf1: 0.8618, (best 0.8785)\n",
            "Epoch 94, loss: 0.0631, val mf1: 0.8618, (best 0.8785)\n",
            "Epoch 95, loss: 0.0618, val mf1: 0.8602, (best 0.8785)\n",
            "Epoch 96, loss: 0.0606, val mf1: 0.8602, (best 0.8785)\n",
            "Epoch 97, loss: 0.0594, val mf1: 0.8602, (best 0.8785)\n",
            "Epoch 98, loss: 0.0583, val mf1: 0.8602, (best 0.8785)\n",
            "Epoch 99, loss: 0.0574, val mf1: 0.8602, (best 0.8785)\n",
            "Epoch 100, loss: 0.0564, val mf1: 0.8578, (best 0.8785)\n",
            "Epoch 101, loss: 0.0554, val mf1: 0.8570, (best 0.8785)\n",
            "Epoch 102, loss: 0.0542, val mf1: 0.8597, (best 0.8785)\n",
            "Epoch 103, loss: 0.0531, val mf1: 0.8638, (best 0.8785)\n",
            "Epoch 104, loss: 0.0521, val mf1: 0.8638, (best 0.8785)\n",
            "Epoch 105, loss: 0.0509, val mf1: 0.8638, (best 0.8785)\n",
            "Epoch 106, loss: 0.0498, val mf1: 0.8638, (best 0.8785)\n",
            "Epoch 107, loss: 0.0489, val mf1: 0.8626, (best 0.8785)\n",
            "Epoch 108, loss: 0.0480, val mf1: 0.8618, (best 0.8785)\n",
            "Epoch 109, loss: 0.0470, val mf1: 0.8630, (best 0.8785)\n",
            "Epoch 110, loss: 0.0470, val mf1: 0.8650, (best 0.8785)\n",
            "Epoch 111, loss: 0.0455, val mf1: 0.8638, (best 0.8785)\n",
            "Epoch 112, loss: 0.0450, val mf1: 0.8642, (best 0.8785)\n",
            "Epoch 113, loss: 0.0442, val mf1: 0.8634, (best 0.8785)\n",
            "Epoch 114, loss: 0.0434, val mf1: 0.8646, (best 0.8785)\n",
            "Epoch 115, loss: 0.0426, val mf1: 0.8650, (best 0.8785)\n",
            "Epoch 116, loss: 0.0417, val mf1: 0.8624, (best 0.8785)\n",
            "Epoch 117, loss: 0.0408, val mf1: 0.8591, (best 0.8785)\n",
            "Epoch 118, loss: 0.0401, val mf1: 0.8596, (best 0.8785)\n",
            "Epoch 119, loss: 0.0395, val mf1: 0.8604, (best 0.8785)\n",
            "Epoch 120, loss: 0.0386, val mf1: 0.8616, (best 0.8785)\n",
            "Epoch 121, loss: 0.0377, val mf1: 0.8632, (best 0.8785)\n",
            "Epoch 122, loss: 0.0371, val mf1: 0.8641, (best 0.8785)\n",
            "Epoch 123, loss: 0.0362, val mf1: 0.8624, (best 0.8785)\n",
            "Epoch 124, loss: 0.0355, val mf1: 0.8600, (best 0.8785)\n",
            "Epoch 125, loss: 0.0348, val mf1: 0.8621, (best 0.8785)\n",
            "Epoch 126, loss: 0.0340, val mf1: 0.8607, (best 0.8785)\n",
            "Epoch 127, loss: 0.0333, val mf1: 0.8623, (best 0.8785)\n",
            "Epoch 128, loss: 0.0326, val mf1: 0.8631, (best 0.8785)\n",
            "Epoch 129, loss: 0.0319, val mf1: 0.8615, (best 0.8785)\n",
            "Epoch 130, loss: 0.0313, val mf1: 0.8598, (best 0.8785)\n",
            "Epoch 131, loss: 0.0306, val mf1: 0.8598, (best 0.8785)\n",
            "Epoch 132, loss: 0.0300, val mf1: 0.8607, (best 0.8785)\n",
            "Epoch 133, loss: 0.0293, val mf1: 0.8623, (best 0.8785)\n",
            "Epoch 134, loss: 0.0291, val mf1: 0.8656, (best 0.8785)\n",
            "Epoch 135, loss: 0.0285, val mf1: 0.8631, (best 0.8785)\n",
            "Epoch 136, loss: 0.0282, val mf1: 0.8631, (best 0.8785)\n",
            "Epoch 137, loss: 0.0278, val mf1: 0.8682, (best 0.8785)\n",
            "Epoch 138, loss: 0.0272, val mf1: 0.8682, (best 0.8785)\n",
            "Epoch 139, loss: 0.0267, val mf1: 0.8673, (best 0.8785)\n",
            "Epoch 140, loss: 0.0261, val mf1: 0.8682, (best 0.8785)\n",
            "Epoch 141, loss: 0.0253, val mf1: 0.8707, (best 0.8785)\n",
            "Epoch 142, loss: 0.0248, val mf1: 0.8707, (best 0.8785)\n",
            "Epoch 143, loss: 0.0241, val mf1: 0.8656, (best 0.8785)\n",
            "Epoch 144, loss: 0.0236, val mf1: 0.8665, (best 0.8785)\n",
            "Epoch 145, loss: 0.0231, val mf1: 0.8724, (best 0.8785)\n",
            "Epoch 146, loss: 0.0229, val mf1: 0.8724, (best 0.8785)\n",
            "Epoch 147, loss: 0.0223, val mf1: 0.8699, (best 0.8785)\n",
            "Epoch 148, loss: 0.0221, val mf1: 0.8699, (best 0.8785)\n",
            "Epoch 149, loss: 0.0216, val mf1: 0.8699, (best 0.8785)\n",
            "Epoch 150, loss: 0.0211, val mf1: 0.8690, (best 0.8785)\n",
            "Epoch 151, loss: 0.0205, val mf1: 0.8724, (best 0.8785)\n",
            "Epoch 152, loss: 0.0200, val mf1: 0.8755, (best 0.8785)\n",
            "Epoch 153, loss: 0.0196, val mf1: 0.8720, (best 0.8785)\n",
            "Epoch 154, loss: 0.0192, val mf1: 0.8720, (best 0.8785)\n",
            "Epoch 155, loss: 0.0187, val mf1: 0.8712, (best 0.8785)\n",
            "Epoch 156, loss: 0.0185, val mf1: 0.8729, (best 0.8785)\n",
            "Epoch 157, loss: 0.0181, val mf1: 0.8729, (best 0.8785)\n",
            "Epoch 158, loss: 0.0177, val mf1: 0.8729, (best 0.8785)\n",
            "Epoch 159, loss: 0.0173, val mf1: 0.8729, (best 0.8785)\n",
            "Epoch 160, loss: 0.0170, val mf1: 0.8724, (best 0.8785)\n",
            "Epoch 161, loss: 0.0167, val mf1: 0.8699, (best 0.8785)\n",
            "Epoch 162, loss: 0.0166, val mf1: 0.8690, (best 0.8785)\n",
            "Epoch 163, loss: 0.0162, val mf1: 0.8699, (best 0.8785)\n",
            "Epoch 164, loss: 0.0158, val mf1: 0.8707, (best 0.8785)\n",
            "Epoch 165, loss: 0.0154, val mf1: 0.8716, (best 0.8785)\n",
            "Epoch 166, loss: 0.0149, val mf1: 0.8724, (best 0.8785)\n",
            "Epoch 167, loss: 0.0152, val mf1: 0.8724, (best 0.8785)\n",
            "Epoch 168, loss: 0.0146, val mf1: 0.8690, (best 0.8785)\n",
            "Epoch 169, loss: 0.0144, val mf1: 0.8682, (best 0.8785)\n",
            "Epoch 170, loss: 0.0141, val mf1: 0.8690, (best 0.8785)\n",
            "Epoch 171, loss: 0.0139, val mf1: 0.8724, (best 0.8785)\n",
            "Epoch 172, loss: 0.0135, val mf1: 0.8716, (best 0.8785)\n",
            "Epoch 173, loss: 0.0131, val mf1: 0.8707, (best 0.8785)\n",
            "Epoch 174, loss: 0.0129, val mf1: 0.8707, (best 0.8785)\n",
            "Epoch 175, loss: 0.0128, val mf1: 0.8707, (best 0.8785)\n",
            "Epoch 176, loss: 0.0124, val mf1: 0.8699, (best 0.8785)\n",
            "Epoch 177, loss: 0.0123, val mf1: 0.8716, (best 0.8785)\n",
            "Epoch 178, loss: 0.0121, val mf1: 0.8707, (best 0.8785)\n",
            "Epoch 179, loss: 0.0118, val mf1: 0.8699, (best 0.8785)\n",
            "Epoch 180, loss: 0.0117, val mf1: 0.8699, (best 0.8785)\n",
            "Epoch 181, loss: 0.0114, val mf1: 0.8703, (best 0.8785)\n",
            "Epoch 182, loss: 0.0111, val mf1: 0.8703, (best 0.8785)\n",
            "Epoch 183, loss: 0.0108, val mf1: 0.8703, (best 0.8785)\n",
            "Epoch 184, loss: 0.0106, val mf1: 0.8711, (best 0.8785)\n",
            "Epoch 185, loss: 0.0103, val mf1: 0.8703, (best 0.8785)\n",
            "Epoch 186, loss: 0.0103, val mf1: 0.8720, (best 0.8785)\n",
            "Epoch 187, loss: 0.0099, val mf1: 0.8724, (best 0.8785)\n",
            "Epoch 188, loss: 0.0097, val mf1: 0.8724, (best 0.8785)\n",
            "Epoch 189, loss: 0.0096, val mf1: 0.8733, (best 0.8785)\n",
            "Epoch 190, loss: 0.0094, val mf1: 0.8703, (best 0.8785)\n",
            "Epoch 191, loss: 0.0093, val mf1: 0.8703, (best 0.8785)\n",
            "Epoch 192, loss: 0.0091, val mf1: 0.8711, (best 0.8785)\n",
            "Epoch 193, loss: 0.0089, val mf1: 0.8729, (best 0.8785)\n",
            "Epoch 194, loss: 0.0087, val mf1: 0.8729, (best 0.8785)\n",
            "Epoch 195, loss: 0.0086, val mf1: 0.8711, (best 0.8785)\n",
            "Epoch 196, loss: 0.0084, val mf1: 0.8711, (best 0.8785)\n",
            "Epoch 197, loss: 0.0083, val mf1: 0.8703, (best 0.8785)\n",
            "Epoch 198, loss: 0.0082, val mf1: 0.8703, (best 0.8785)\n",
            "Epoch 199, loss: 0.0080, val mf1: 0.8711, (best 0.8785)\n",
            "time cost:  342.43020391464233 s\n",
            "Test: REC 80.00 PRE 72.13 MF1 86.59 AUC 95.16\n"
          ]
        }
      ],
      "source": [
        "!python main.py --dataset amazon --train_ratio 0.1 --hid_dim 64 --order 2 --homo 0 --epoch 200 --run 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEcMKyY1rWea",
        "outputId": "20215e10-0300-407e-cd5e-e6133d42e73a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/FRAUDRE-main\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/FRAUDRE-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-C8-ldtdrxsy",
        "outputId": "c58011b7-354e-451d-ff14-904cd67b5627"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda is available\n",
            "runing with GPU\n",
            "run on yelp\n",
            "Epoch: 0, batch: 0\n",
            "Epoch: 0, batch: 1\n",
            "Epoch: 0, batch: 2\n",
            "Epoch: 0, batch: 3\n",
            "Epoch: 0, batch: 4\n",
            "Epoch: 0, batch: 5\n",
            "Epoch: 0, batch: 6\n",
            "Epoch: 0, batch: 7\n",
            "Epoch: 0, batch: 8\n",
            "Epoch: 0, loss: 0.08930589404992909, time: 36.797176361083984, otime: 36.797176361083984s\n",
            "Test: REC 49.76 MF1 46.07 AUC 55.71\n",
            "Epoch: 1, batch: 0\n",
            "Epoch: 1, batch: 1\n",
            "Epoch: 1, batch: 2\n",
            "Epoch: 1, batch: 3\n",
            "Epoch: 1, batch: 4\n",
            "Epoch: 1, batch: 5\n",
            "Epoch: 1, batch: 6\n",
            "Epoch: 1, batch: 7\n",
            "Epoch: 1, batch: 8\n",
            "Epoch: 1, loss: 0.09248287849170199, time: 33.92235541343689, otime: 70.71953177452087s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 2, batch: 0\n",
            "Epoch: 2, batch: 1\n",
            "Epoch: 2, batch: 2\n",
            "Epoch: 2, batch: 3\n",
            "Epoch: 2, batch: 4\n",
            "Epoch: 2, batch: 5\n",
            "Epoch: 2, batch: 6\n",
            "Epoch: 2, batch: 7\n",
            "Epoch: 2, batch: 8\n",
            "Epoch: 2, loss: 0.0913013444133427, time: 33.88061761856079, otime: 104.60014939308167s\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 3, batch: 0\n",
            "Epoch: 3, batch: 1\n",
            "Epoch: 3, batch: 2\n",
            "Epoch: 3, batch: 3\n",
            "Epoch: 3, batch: 4\n",
            "Epoch: 3, batch: 5\n",
            "Epoch: 3, batch: 6\n",
            "Epoch: 3, batch: 7\n",
            "Epoch: 3, batch: 8\n",
            "Epoch: 3, loss: 0.09285532604526653, time: 33.87071704864502, otime: 138.47086644172668s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 4, batch: 0\n",
            "Epoch: 4, batch: 1\n",
            "Epoch: 4, batch: 2\n",
            "Epoch: 4, batch: 3\n",
            "Epoch: 4, batch: 4\n",
            "Epoch: 4, batch: 5\n",
            "Epoch: 4, batch: 6\n",
            "Epoch: 4, batch: 7\n",
            "Epoch: 4, batch: 8\n",
            "Epoch: 4, loss: 0.09484030044508522, time: 34.22108578681946, otime: 172.69195222854614s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 5, batch: 0\n",
            "Epoch: 5, batch: 1\n",
            "Epoch: 5, batch: 2\n",
            "Epoch: 5, batch: 3\n",
            "Epoch: 5, batch: 4\n",
            "Epoch: 5, batch: 5\n",
            "Epoch: 5, batch: 6\n",
            "Epoch: 5, batch: 7\n",
            "Epoch: 5, batch: 8\n",
            "Epoch: 5, loss: 0.09164256625828601, time: 34.12604832649231, otime: 206.81800055503845s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 6, batch: 0\n",
            "Epoch: 6, batch: 1\n",
            "Epoch: 6, batch: 2\n",
            "Epoch: 6, batch: 3\n",
            "Epoch: 6, batch: 4\n",
            "Epoch: 6, batch: 5\n",
            "Epoch: 6, batch: 6\n",
            "Epoch: 6, batch: 7\n",
            "Epoch: 6, batch: 8\n",
            "Epoch: 6, loss: 0.09436475937816036, time: 34.61620020866394, otime: 241.4342007637024s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 7, batch: 0\n",
            "Epoch: 7, batch: 1\n",
            "Epoch: 7, batch: 2\n",
            "Epoch: 7, batch: 3\n",
            "Epoch: 7, batch: 4\n",
            "Epoch: 7, batch: 5\n",
            "Epoch: 7, batch: 6\n",
            "Epoch: 7, batch: 7\n",
            "Epoch: 7, batch: 8\n",
            "Epoch: 7, loss: 0.09313407932445877, time: 34.71520709991455, otime: 276.14940786361694s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 8, batch: 0\n",
            "Epoch: 8, batch: 1\n",
            "Epoch: 8, batch: 2\n",
            "Epoch: 8, batch: 3\n",
            "Epoch: 8, batch: 4\n",
            "Epoch: 8, batch: 5\n",
            "Epoch: 8, batch: 6\n",
            "Epoch: 8, batch: 7\n",
            "Epoch: 8, batch: 8\n",
            "Epoch: 8, loss: 0.08797686412408563, time: 34.37845993041992, otime: 310.52786779403687s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 9, batch: 0\n",
            "Epoch: 9, batch: 1\n",
            "Epoch: 9, batch: 2\n",
            "Epoch: 9, batch: 3\n",
            "Epoch: 9, batch: 4\n",
            "Epoch: 9, batch: 5\n",
            "Epoch: 9, batch: 6\n",
            "Epoch: 9, batch: 7\n",
            "Epoch: 9, batch: 8\n",
            "Epoch: 9, loss: 0.08226899708497727, time: 34.59912037849426, otime: 345.1269881725311s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 10, batch: 0\n",
            "Epoch: 10, batch: 1\n",
            "Epoch: 10, batch: 2\n",
            "Epoch: 10, batch: 3\n",
            "Epoch: 10, batch: 4\n",
            "Epoch: 10, batch: 5\n",
            "Epoch: 10, batch: 6\n",
            "Epoch: 10, batch: 7\n",
            "Epoch: 10, batch: 8\n",
            "Epoch: 10, loss: 0.09079822650093533, time: 34.6003623008728, otime: 379.72735047340393s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 11, batch: 0\n",
            "Epoch: 11, batch: 1\n",
            "Epoch: 11, batch: 2\n",
            "Epoch: 11, batch: 3\n",
            "Epoch: 11, batch: 4\n",
            "Epoch: 11, batch: 5\n",
            "Epoch: 11, batch: 6\n",
            "Epoch: 11, batch: 7\n",
            "Epoch: 11, batch: 8\n",
            "Epoch: 11, loss: 0.0939936207299478, time: 34.600197315216064, otime: 414.32754778862s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 12, batch: 0\n",
            "Epoch: 12, batch: 1\n",
            "Epoch: 12, batch: 2\n",
            "Epoch: 12, batch: 3\n",
            "Epoch: 12, batch: 4\n",
            "Epoch: 12, batch: 5\n",
            "Epoch: 12, batch: 6\n",
            "Epoch: 12, batch: 7\n",
            "Epoch: 12, batch: 8\n",
            "Epoch: 12, loss: 0.09316590225819384, time: 34.76414370536804, otime: 449.09169149398804s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 13, batch: 0\n",
            "Epoch: 13, batch: 1\n",
            "Epoch: 13, batch: 2\n",
            "Epoch: 13, batch: 3\n",
            "Epoch: 13, batch: 4\n",
            "Epoch: 13, batch: 5\n",
            "Epoch: 13, batch: 6\n",
            "Epoch: 13, batch: 7\n",
            "Epoch: 13, batch: 8\n",
            "Epoch: 13, loss: 0.09353532048143691, time: 34.788628816604614, otime: 483.88032031059265s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 14, batch: 0\n",
            "Epoch: 14, batch: 1\n",
            "Epoch: 14, batch: 2\n",
            "Epoch: 14, batch: 3\n",
            "Epoch: 14, batch: 4\n",
            "Epoch: 14, batch: 5\n",
            "Epoch: 14, batch: 6\n",
            "Epoch: 14, batch: 7\n",
            "Epoch: 14, batch: 8\n",
            "Epoch: 14, loss: 0.09191601008369764, time: 34.66598725318909, otime: 518.5463075637817s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 15, batch: 0\n",
            "Epoch: 15, batch: 1\n",
            "Epoch: 15, batch: 2\n",
            "Epoch: 15, batch: 3\n",
            "Epoch: 15, batch: 4\n",
            "Epoch: 15, batch: 5\n",
            "Epoch: 15, batch: 6\n",
            "Epoch: 15, batch: 7\n",
            "Epoch: 15, batch: 8\n",
            "Epoch: 15, loss: 0.09706325286002378, time: 34.053542613983154, otime: 552.5998501777649s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 16, batch: 0\n",
            "Epoch: 16, batch: 1\n",
            "Epoch: 16, batch: 2\n",
            "Epoch: 16, batch: 3\n",
            "Epoch: 16, batch: 4\n",
            "Epoch: 16, batch: 5\n",
            "Epoch: 16, batch: 6\n",
            "Epoch: 16, batch: 7\n",
            "Epoch: 16, batch: 8\n",
            "Epoch: 16, loss: 0.09070867101977177, time: 34.46261191368103, otime: 587.0624620914459s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 17, batch: 0\n",
            "Epoch: 17, batch: 1\n",
            "Epoch: 17, batch: 2\n",
            "Epoch: 17, batch: 3\n",
            "Epoch: 17, batch: 4\n",
            "Epoch: 17, batch: 5\n",
            "Epoch: 17, batch: 6\n",
            "Epoch: 17, batch: 7\n",
            "Epoch: 17, batch: 8\n",
            "Epoch: 17, loss: 0.09066074017724007, time: 34.22337460517883, otime: 621.2858366966248s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 18, batch: 0\n",
            "Epoch: 18, batch: 1\n",
            "Epoch: 18, batch: 2\n",
            "Epoch: 18, batch: 3\n",
            "Epoch: 18, batch: 4\n",
            "Epoch: 18, batch: 5\n",
            "Epoch: 18, batch: 6\n",
            "Epoch: 18, batch: 7\n",
            "Epoch: 18, batch: 8\n",
            "Epoch: 18, loss: 0.09267833363582051, time: 34.36409902572632, otime: 655.6499357223511s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 19, batch: 0\n",
            "Epoch: 19, batch: 1\n",
            "Epoch: 19, batch: 2\n",
            "Epoch: 19, batch: 3\n",
            "Epoch: 19, batch: 4\n",
            "Epoch: 19, batch: 5\n",
            "Epoch: 19, batch: 6\n",
            "Epoch: 19, batch: 7\n",
            "Epoch: 19, batch: 8\n",
            "Epoch: 19, loss: 0.09230095427200977, time: 34.63064479827881, otime: 690.2805805206299s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 20, batch: 0\n",
            "Epoch: 20, batch: 1\n",
            "Epoch: 20, batch: 2\n",
            "Epoch: 20, batch: 3\n",
            "Epoch: 20, batch: 4\n",
            "Epoch: 20, batch: 5\n",
            "Epoch: 20, batch: 6\n",
            "Epoch: 20, batch: 7\n",
            "Epoch: 20, batch: 8\n",
            "Epoch: 20, loss: 0.08797498739654377, time: 34.37469458580017, otime: 724.65527510643s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 21, batch: 0\n",
            "Epoch: 21, batch: 1\n",
            "Epoch: 21, batch: 2\n",
            "Epoch: 21, batch: 3\n",
            "Epoch: 21, batch: 4\n",
            "Epoch: 21, batch: 5\n",
            "Epoch: 21, batch: 6\n",
            "Epoch: 21, batch: 7\n",
            "Epoch: 21, batch: 8\n",
            "Epoch: 21, loss: 0.09534576867542238, time: 34.93772053718567, otime: 759.5929956436157s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 22, batch: 0\n",
            "Epoch: 22, batch: 1\n",
            "Epoch: 22, batch: 2\n",
            "Epoch: 22, batch: 3\n",
            "Epoch: 22, batch: 4\n",
            "Epoch: 22, batch: 5\n",
            "Epoch: 22, batch: 6\n",
            "Epoch: 22, batch: 7\n",
            "Epoch: 22, batch: 8\n",
            "Epoch: 22, loss: 0.09528707590367168, time: 34.712934255599976, otime: 794.3059298992157s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 23, batch: 0\n",
            "Epoch: 23, batch: 1\n",
            "Epoch: 23, batch: 2\n",
            "Epoch: 23, batch: 3\n",
            "Epoch: 23, batch: 4\n",
            "Epoch: 23, batch: 5\n",
            "Epoch: 23, batch: 6\n",
            "Epoch: 23, batch: 7\n",
            "Epoch: 23, batch: 8\n",
            "Epoch: 23, loss: 0.0937669488643096, time: 34.203659772872925, otime: 828.5095896720886s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 24, batch: 0\n",
            "Epoch: 24, batch: 1\n",
            "Epoch: 24, batch: 2\n",
            "Epoch: 24, batch: 3\n",
            "Epoch: 24, batch: 4\n",
            "Epoch: 24, batch: 5\n",
            "Epoch: 24, batch: 6\n",
            "Epoch: 24, batch: 7\n",
            "Epoch: 24, batch: 8\n",
            "Epoch: 24, loss: 0.0958713499835394, time: 34.528735637664795, otime: 863.0383253097534s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 25, batch: 0\n",
            "Epoch: 25, batch: 1\n",
            "Epoch: 25, batch: 2\n",
            "Epoch: 25, batch: 3\n",
            "Epoch: 25, batch: 4\n",
            "Epoch: 25, batch: 5\n",
            "Epoch: 25, batch: 6\n",
            "Epoch: 25, batch: 7\n",
            "Epoch: 25, batch: 8\n",
            "Epoch: 25, loss: 0.09009881207410082, time: 34.3544716835022, otime: 897.3927969932556s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 26, batch: 0\n",
            "Epoch: 26, batch: 1\n",
            "Epoch: 26, batch: 2\n",
            "Epoch: 26, batch: 3\n",
            "Epoch: 26, batch: 4\n",
            "Epoch: 26, batch: 5\n",
            "Epoch: 26, batch: 6\n",
            "Epoch: 26, batch: 7\n",
            "Epoch: 26, batch: 8\n",
            "Epoch: 26, loss: 0.08809782773794003, time: 34.65002751350403, otime: 932.0428245067596s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 27, batch: 0\n",
            "Epoch: 27, batch: 1\n",
            "Epoch: 27, batch: 2\n",
            "Epoch: 27, batch: 3\n",
            "Epoch: 27, batch: 4\n",
            "Epoch: 27, batch: 5\n",
            "Epoch: 27, batch: 6\n",
            "Epoch: 27, batch: 7\n",
            "Epoch: 27, batch: 8\n",
            "Epoch: 27, loss: 0.08802209234028123, time: 34.49326300621033, otime: 966.53608751297s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 28, batch: 0\n",
            "Epoch: 28, batch: 1\n",
            "Epoch: 28, batch: 2\n",
            "Epoch: 28, batch: 3\n",
            "Epoch: 28, batch: 4\n",
            "Epoch: 28, batch: 5\n",
            "Epoch: 28, batch: 6\n",
            "Epoch: 28, batch: 7\n",
            "Epoch: 28, batch: 8\n",
            "Epoch: 28, loss: 0.08949765182983398, time: 34.867594957351685, otime: 1001.4036824703217s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 29, batch: 0\n",
            "Epoch: 29, batch: 1\n",
            "Epoch: 29, batch: 2\n",
            "Epoch: 29, batch: 3\n",
            "Epoch: 29, batch: 4\n",
            "Epoch: 29, batch: 5\n",
            "Epoch: 29, batch: 6\n",
            "Epoch: 29, batch: 7\n",
            "Epoch: 29, batch: 8\n",
            "Epoch: 29, loss: 0.08963837604294767, time: 34.29932260513306, otime: 1035.7030050754547s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 30, batch: 0\n",
            "Epoch: 30, batch: 1\n",
            "Epoch: 30, batch: 2\n",
            "Epoch: 30, batch: 3\n",
            "Epoch: 30, batch: 4\n",
            "Epoch: 30, batch: 5\n",
            "Epoch: 30, batch: 6\n",
            "Epoch: 30, batch: 7\n",
            "Epoch: 30, batch: 8\n",
            "Epoch: 30, loss: 0.09160797319221078, time: 34.53465414047241, otime: 1070.2376592159271s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 31, batch: 0\n",
            "Epoch: 31, batch: 1\n",
            "Epoch: 31, batch: 2\n",
            "Epoch: 31, batch: 3\n",
            "Epoch: 31, batch: 4\n",
            "Epoch: 31, batch: 5\n",
            "Epoch: 31, batch: 6\n",
            "Epoch: 31, batch: 7\n",
            "Epoch: 31, batch: 8\n",
            "Epoch: 31, loss: 0.09038121710834028, time: 34.71968078613281, otime: 1104.95734000206s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 32, batch: 0\n",
            "Epoch: 32, batch: 1\n",
            "Epoch: 32, batch: 2\n",
            "Epoch: 32, batch: 3\n",
            "Epoch: 32, batch: 4\n",
            "Epoch: 32, batch: 5\n",
            "Epoch: 32, batch: 6\n",
            "Epoch: 32, batch: 7\n",
            "Epoch: 32, batch: 8\n",
            "Epoch: 32, loss: 0.08762305323406198, time: 34.75159025192261, otime: 1139.7089302539825s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 33, batch: 0\n",
            "Epoch: 33, batch: 1\n",
            "Epoch: 33, batch: 2\n",
            "Epoch: 33, batch: 3\n",
            "Epoch: 33, batch: 4\n",
            "Epoch: 33, batch: 5\n",
            "Epoch: 33, batch: 6\n",
            "Epoch: 33, batch: 7\n",
            "Epoch: 33, batch: 8\n",
            "Epoch: 33, loss: 0.09339668465488911, time: 34.49012994766235, otime: 1174.199060201645s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 34, batch: 0\n",
            "Epoch: 34, batch: 1\n",
            "Epoch: 34, batch: 2\n",
            "Epoch: 34, batch: 3\n",
            "Epoch: 34, batch: 4\n",
            "Epoch: 34, batch: 5\n",
            "Epoch: 34, batch: 6\n",
            "Epoch: 34, batch: 7\n",
            "Epoch: 34, batch: 8\n",
            "Epoch: 34, loss: 0.08940121531692036, time: 34.24805045127869, otime: 1208.4471106529236s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 35, batch: 0\n",
            "Epoch: 35, batch: 1\n",
            "Epoch: 35, batch: 2\n",
            "Epoch: 35, batch: 3\n",
            "Epoch: 35, batch: 4\n",
            "Epoch: 35, batch: 5\n",
            "Epoch: 35, batch: 6\n",
            "Epoch: 35, batch: 7\n",
            "Epoch: 35, batch: 8\n",
            "Epoch: 35, loss: 0.09240315900152027, time: 33.96752858161926, otime: 1242.4146392345428s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 36, batch: 0\n",
            "Epoch: 36, batch: 1\n",
            "Epoch: 36, batch: 2\n",
            "Epoch: 36, batch: 3\n",
            "Epoch: 36, batch: 4\n",
            "Epoch: 36, batch: 5\n",
            "Epoch: 36, batch: 6\n",
            "Epoch: 36, batch: 7\n",
            "Epoch: 36, batch: 8\n",
            "Epoch: 36, loss: 0.08554710917187168, time: 34.30088758468628, otime: 1276.7155268192291s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 37, batch: 0\n",
            "Epoch: 37, batch: 1\n",
            "Epoch: 37, batch: 2\n",
            "Epoch: 37, batch: 3\n",
            "Epoch: 37, batch: 4\n",
            "Epoch: 37, batch: 5\n",
            "Epoch: 37, batch: 6\n",
            "Epoch: 37, batch: 7\n",
            "Epoch: 37, batch: 8\n",
            "Epoch: 37, loss: 0.0881305234536449, time: 34.250553131103516, otime: 1310.9660799503326s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 38, batch: 0\n",
            "Epoch: 38, batch: 1\n",
            "Epoch: 38, batch: 2\n",
            "Epoch: 38, batch: 3\n",
            "Epoch: 38, batch: 4\n",
            "Epoch: 38, batch: 5\n",
            "Epoch: 38, batch: 6\n",
            "Epoch: 38, batch: 7\n",
            "Epoch: 38, batch: 8\n",
            "Epoch: 38, loss: 0.09048542818305397, time: 34.48096466064453, otime: 1345.4470446109772s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 39, batch: 0\n",
            "Epoch: 39, batch: 1\n",
            "Epoch: 39, batch: 2\n",
            "Epoch: 39, batch: 3\n",
            "Epoch: 39, batch: 4\n",
            "Epoch: 39, batch: 5\n",
            "Epoch: 39, batch: 6\n",
            "Epoch: 39, batch: 7\n",
            "Epoch: 39, batch: 8\n",
            "Epoch: 39, loss: 0.09475353612736867, time: 34.26491832733154, otime: 1379.7119629383087s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 40, batch: 0\n",
            "Epoch: 40, batch: 1\n",
            "Epoch: 40, batch: 2\n",
            "Epoch: 40, batch: 3\n",
            "Epoch: 40, batch: 4\n",
            "Epoch: 40, batch: 5\n",
            "Epoch: 40, batch: 6\n",
            "Epoch: 40, batch: 7\n",
            "Epoch: 40, batch: 8\n",
            "Epoch: 40, loss: 0.09635983559044893, time: 34.37991166114807, otime: 1414.0918745994568s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 41, batch: 0\n",
            "Epoch: 41, batch: 1\n",
            "Epoch: 41, batch: 2\n",
            "Epoch: 41, batch: 3\n",
            "Epoch: 41, batch: 4\n",
            "Epoch: 41, batch: 5\n",
            "Epoch: 41, batch: 6\n",
            "Epoch: 41, batch: 7\n",
            "Epoch: 41, batch: 8\n",
            "Epoch: 41, loss: 0.09451633628776479, time: 34.75684976577759, otime: 1448.8487243652344s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 42, batch: 0\n",
            "Epoch: 42, batch: 1\n",
            "Epoch: 42, batch: 2\n",
            "Epoch: 42, batch: 3\n",
            "Epoch: 42, batch: 4\n",
            "Epoch: 42, batch: 5\n",
            "Epoch: 42, batch: 6\n",
            "Epoch: 42, batch: 7\n",
            "Epoch: 42, batch: 8\n",
            "Epoch: 42, loss: 0.08796162756632403, time: 34.30993056297302, otime: 1483.1586549282074s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 43, batch: 0\n",
            "Epoch: 43, batch: 1\n",
            "Epoch: 43, batch: 2\n",
            "Epoch: 43, batch: 3\n",
            "Epoch: 43, batch: 4\n",
            "Epoch: 43, batch: 5\n",
            "Epoch: 43, batch: 6\n",
            "Epoch: 43, batch: 7\n",
            "Epoch: 43, batch: 8\n",
            "Epoch: 43, loss: 0.0896882670544748, time: 34.57958173751831, otime: 1517.7382366657257s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 44, batch: 0\n",
            "Epoch: 44, batch: 1\n",
            "Epoch: 44, batch: 2\n",
            "Epoch: 44, batch: 3\n",
            "Epoch: 44, batch: 4\n",
            "Epoch: 44, batch: 5\n",
            "Epoch: 44, batch: 6\n",
            "Epoch: 44, batch: 7\n",
            "Epoch: 44, batch: 8\n",
            "Epoch: 44, loss: 0.09521007841216372, time: 34.4932918548584, otime: 1552.231528520584s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 45, batch: 0\n",
            "Epoch: 45, batch: 1\n",
            "Epoch: 45, batch: 2\n",
            "Epoch: 45, batch: 3\n",
            "Epoch: 45, batch: 4\n",
            "Epoch: 45, batch: 5\n",
            "Epoch: 45, batch: 6\n",
            "Epoch: 45, batch: 7\n",
            "Epoch: 45, batch: 8\n",
            "Epoch: 45, loss: 0.08972195170029057, time: 34.71669936180115, otime: 1586.9482278823853s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 46, batch: 0\n",
            "Epoch: 46, batch: 1\n",
            "Epoch: 46, batch: 2\n",
            "Epoch: 46, batch: 3\n",
            "Epoch: 46, batch: 4\n",
            "Epoch: 46, batch: 5\n",
            "Epoch: 46, batch: 6\n",
            "Epoch: 46, batch: 7\n",
            "Epoch: 46, batch: 8\n",
            "Epoch: 46, loss: 0.09027746070864026, time: 34.406129598617554, otime: 1621.3543574810028s\n",
            "Test: REC 52.20 MF1 18.55 AUC 56.95\n",
            "Epoch: 47, batch: 0\n",
            "Epoch: 47, batch: 1\n",
            "Epoch: 47, batch: 2\n",
            "Epoch: 47, batch: 3\n",
            "Epoch: 47, batch: 4\n",
            "Epoch: 47, batch: 5\n",
            "Epoch: 47, batch: 6\n",
            "\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!python train.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjaLuyvyaikD",
        "outputId": "6328dbd8-c60f-4e9f-8c91-79be58076118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/PC-GNN-main/PC-GNN-main\n"
          ]
        }
      ],
      "source": [
        "cd /content/drive/MyDrive/PC-GNN-main/PC-GNN-main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP0vIwF8amL7",
        "outputId": "e64c6fa2-9ed6-47f3-8ec6-08020a8b1705"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**************** MODEL CONFIGURATION ****************\n",
            "alpha                    -->   2\n",
            "batch_size               -->   256\n",
            "cuda_id                  -->   0\n",
            "data_dir                 -->   ./src/data/\n",
            "data_name                -->   amazon\n",
            "emb_size                 -->   64\n",
            "lr                       -->   0.001\n",
            "model                    -->   PCGNN\n",
            "multi_relation           -->   GNN\n",
            "no_cuda                  -->   False\n",
            "num_epochs               -->   100\n",
            "optimizer                -->   adam\n",
            "rho                      -->   0.5\n",
            "save_dir                 -->   ./pytorch_models/\n",
            "seed                     -->   72\n",
            "test_ratio               -->   0.67\n",
            "thres                    -->   0.4\n",
            "train_ratio              -->   0.4\n",
            "valid_epochs             -->   5\n",
            "weight_decay             -->   0.0005\n",
            "**************** MODEL CONFIGURATION ****************\n",
            "Run on amazon, postive/total num: 821.0/11944, train num 4777,valid num 2365, test num 4802, test positive num 330.0\n",
            "Classification threshold: 0.4\n",
            "Feature dimension: 25\n",
            "Model: PCGNN, multi-relation aggregator: GNN, emb_size: 64.\n",
            "Epoch: 0, loss: 1.3173295656840007, time: 2.3404204845428467s\n",
            "Valid at epoch 0\n",
            "   GNN F1-binary-1: 0.1290\tF1-binary-0: 0.0000\tF1-macro: 0.0645\tG-Mean: 0.0000\tAUC: 0.7549\tREC: 0.5000\n",
            "   GNN TP: 163\tTN: 0\tFN: 0\tFP: 2202\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.1561\tAP: 0.0385\n",
            "   GNN F1-binary-1: 0.1286\tF1-binary-0: 0.0000\tF1-macro: 0.0643\tG-Mean: 0.0000\tAUC: 0.7203\tREC: 0.5000\n",
            "   GNN TP: 330\tTN: 0\tFN: 0\tFP: 4472\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.1678\tAP: 0.0386\n",
            "\tF1-macro: 0.0643\tAUC: 0.7203\tREC: 0.5000\n",
            "  Saving model ...\n",
            "Epoch: 1, loss: 1.3131688435872395, time: 1.599766492843628s\n",
            "Epoch: 2, loss: 1.2674466768900554, time: 1.646237850189209s\n",
            "Epoch: 3, loss: 1.2316001256306965, time: 1.5834131240844727s\n",
            "Epoch: 4, loss: 1.2324443658192952, time: 1.6663320064544678s\n",
            "Epoch: 5, loss: 1.2409571011861165, time: 1.580272912979126s\n",
            "Valid at epoch 5\n",
            "   GNN F1-binary-1: 0.5283\tF1-binary-0: 0.9405\tF1-macro: 0.7344\tG-Mean: 0.8777\tAUC: 0.9280\tREC: 0.8779\n",
            "   GNN TP: 140\tTN: 1975\tFN: 23\tFP: 227\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.2028\tAP: 0.0402\n",
            "   GNN F1-binary-1: 0.4922\tF1-binary-0: 0.9353\tF1-macro: 0.7137\tG-Mean: 0.8490\tAUC: 0.9127\tREC: 0.8500\n",
            "   GNN TP: 267\tTN: 3984\tFN: 63\tFP: 488\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.2345\tAP: 0.0415\n",
            "\tF1-macro: 0.7137\tAUC: 0.9127\tREC: 0.8500\n",
            "  Saving model ...\n",
            "Epoch: 6, loss: 1.2060773372650146, time: 1.5567538738250732s\n",
            "Epoch: 7, loss: 1.2252481778462727, time: 1.5927059650421143s\n",
            "Epoch: 8, loss: 1.1515063444773357, time: 1.5780084133148193s\n",
            "Epoch: 9, loss: 1.14537517229716, time: 1.6326756477355957s\n",
            "Epoch: 10, loss: 1.1580584049224854, time: 1.6294491291046143s\n",
            "Valid at epoch 10\n",
            "   GNN F1-binary-1: 0.6699\tF1-binary-0: 0.9685\tF1-macro: 0.8192\tG-Mean: 0.8966\tAUC: 0.9296\tREC: 0.8981\n",
            "   GNN TP: 138\tTN: 2091\tFN: 25\tFP: 111\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.2862\tAP: 0.0444\n",
            "   GNN F1-binary-1: 0.6157\tF1-binary-0: 0.9626\tF1-macro: 0.7892\tG-Mean: 0.8648\tAUC: 0.9095\tREC: 0.8680\n",
            "   GNN TP: 262\tTN: 4213\tFN: 68\tFP: 259\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.3180\tAP: 0.0463\n",
            "\tF1-macro: 0.7892\tAUC: 0.9095\tREC: 0.8680\n",
            "  Saving model ...\n",
            "Epoch: 11, loss: 1.133223056793213, time: 1.6416113376617432s\n",
            "Epoch: 12, loss: 1.2275759379069011, time: 1.6284644603729248s\n",
            "Epoch: 13, loss: 1.1086339155832927, time: 1.5893840789794922s\n",
            "Epoch: 14, loss: 1.1032236417134602, time: 1.5945265293121338s\n",
            "Epoch: 15, loss: 1.155839204788208, time: 1.6174025535583496s\n",
            "Valid at epoch 15\n",
            "   GNN F1-binary-1: 0.6715\tF1-binary-0: 0.9685\tF1-macro: 0.8200\tG-Mean: 0.8997\tAUC: 0.9499\tREC: 0.9009\n",
            "   GNN TP: 139\tTN: 2090\tFN: 24\tFP: 112\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.3990\tAP: 0.0522\n",
            "   GNN F1-binary-1: 0.5978\tF1-binary-0: 0.9589\tF1-macro: 0.7783\tG-Mean: 0.8678\tAUC: 0.9366\tREC: 0.8702\n",
            "   GNN TP: 266\tTN: 4178\tFN: 64\tFP: 294\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.4132\tAP: 0.0532\n",
            "\tF1-macro: 0.7783\tAUC: 0.9366\tREC: 0.8702\n",
            "  Saving model ...\n",
            "Epoch: 16, loss: 1.124497413635254, time: 1.5523293018341064s\n",
            "Epoch: 17, loss: 1.0789635181427002, time: 2.256258487701416s\n",
            "Epoch: 18, loss: 1.045133352279663, time: 1.626796007156372s\n",
            "Epoch: 19, loss: 1.0989707310994465, time: 1.6014049053192139s\n",
            "Epoch: 20, loss: 1.0683261553446453, time: 1.5692272186279297s\n",
            "Valid at epoch 20\n",
            "   GNN F1-binary-1: 0.7541\tF1-binary-0: 0.9794\tF1-macro: 0.8667\tG-Mean: 0.9064\tAUC: 0.9551\tREC: 0.9086\n",
            "   GNN TP: 138\tTN: 2137\tFN: 25\tFP: 65\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.5028\tAP: 0.0630\n",
            "   GNN F1-binary-1: 0.6859\tF1-binary-0: 0.9729\tF1-macro: 0.8294\tG-Mean: 0.8737\tAUC: 0.9436\tREC: 0.8777\n",
            "   GNN TP: 262\tTN: 4300\tFN: 68\tFP: 172\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.5148\tAP: 0.0642\n",
            "\tF1-macro: 0.8294\tAUC: 0.9436\tREC: 0.8777\n",
            "  Saving model ...\n",
            "Epoch: 21, loss: 1.0460407733917236, time: 1.5428156852722168s\n",
            "Epoch: 22, loss: 1.0358649889628093, time: 1.5894734859466553s\n",
            "Epoch: 23, loss: 1.0256266593933105, time: 1.5850396156311035s\n",
            "Epoch: 24, loss: 1.10258952776591, time: 1.622819423675537s\n",
            "Epoch: 25, loss: 1.0942142804463704, time: 1.5796005725860596s\n",
            "Valid at epoch 25\n",
            "   GNN F1-binary-1: 0.6605\tF1-binary-0: 0.9660\tF1-macro: 0.8133\tG-Mean: 0.9065\tAUC: 0.9584\tREC: 0.9072\n",
            "   GNN TP: 142\tTN: 2077\tFN: 21\tFP: 125\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.6241\tAP: 0.0872\n",
            "   GNN F1-binary-1: 0.6018\tF1-binary-0: 0.9581\tF1-macro: 0.7799\tG-Mean: 0.8808\tAUC: 0.9475\tREC: 0.8821\n",
            "   GNN TP: 275\tTN: 4163\tFN: 55\tFP: 309\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.6266\tAP: 0.0891\n",
            "Epoch: 26, loss: 0.9981744289398193, time: 1.6164941787719727s\n",
            "Epoch: 27, loss: 1.0455556710561116, time: 1.5606184005737305s\n",
            "Epoch: 28, loss: 0.9768845240275065, time: 1.5868732929229736s\n",
            "Epoch: 29, loss: 0.9931449890136719, time: 1.5897960662841797s\n",
            "Epoch: 30, loss: 1.008940617243449, time: 1.576348066329956s\n",
            "Valid at epoch 30\n",
            "   GNN F1-binary-1: 0.6980\tF1-binary-0: 0.9718\tF1-macro: 0.8349\tG-Mean: 0.9087\tAUC: 0.9594\tREC: 0.9098\n",
            "   GNN TP: 141\tTN: 2102\tFN: 22\tFP: 100\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.7408\tAP: 0.1471\n",
            "   GNN F1-binary-1: 0.6292\tF1-binary-0: 0.9638\tF1-macro: 0.7965\tG-Mean: 0.8766\tAUC: 0.9501\tREC: 0.8790\n",
            "   GNN TP: 269\tTN: 4216\tFN: 61\tFP: 256\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.7305\tAP: 0.1497\n",
            "Epoch: 31, loss: 1.014715274175008, time: 1.5898709297180176s\n",
            "Epoch: 32, loss: 1.026945432027181, time: 1.617354393005371s\n",
            "Epoch: 33, loss: 1.039021333058675, time: 1.5903644561767578s\n",
            "Epoch: 34, loss: 1.0262269179026287, time: 1.5568883419036865s\n",
            "Epoch: 35, loss: 0.9855127334594727, time: 1.640998363494873s\n",
            "Valid at epoch 35\n",
            "   GNN F1-binary-1: 0.7467\tF1-binary-0: 0.9782\tF1-macro: 0.8624\tG-Mean: 0.9115\tAUC: 0.9623\tREC: 0.9131\n",
            "   GNN TP: 140\tTN: 2130\tFN: 23\tFP: 72\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8117\tAP: 0.2673\n",
            "   GNN F1-binary-1: 0.6818\tF1-binary-0: 0.9713\tF1-macro: 0.8265\tG-Mean: 0.8863\tAUC: 0.9553\tREC: 0.8889\n",
            "   GNN TP: 271\tTN: 4278\tFN: 59\tFP: 194\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.7928\tAP: 0.2684\n",
            "Epoch: 36, loss: 0.9772758483886719, time: 1.6639268398284912s\n",
            "Epoch: 37, loss: 1.000057538350423, time: 1.614060878753662s\n",
            "Epoch: 38, loss: 0.9953988393147787, time: 1.5802581310272217s\n",
            "Epoch: 39, loss: 0.9782614707946777, time: 1.6149744987487793s\n",
            "Epoch: 40, loss: 0.9446243445078532, time: 1.5748188495635986s\n",
            "Valid at epoch 40\n",
            "   GNN F1-binary-1: 0.6606\tF1-binary-0: 0.9655\tF1-macro: 0.8130\tG-Mean: 0.9120\tAUC: 0.9609\tREC: 0.9124\n",
            "   GNN TP: 144\tTN: 2073\tFN: 19\tFP: 129\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8483\tAP: 0.4853\n",
            "   GNN F1-binary-1: 0.5900\tF1-binary-0: 0.9556\tF1-macro: 0.7728\tG-Mean: 0.8815\tAUC: 0.9519\tREC: 0.8826\n",
            "   GNN TP: 277\tTN: 4140\tFN: 53\tFP: 332\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8235\tAP: 0.4477\n",
            "Epoch: 41, loss: 0.9671135743459066, time: 1.601754903793335s\n",
            "Epoch: 42, loss: 1.005338986714681, time: 1.6260216236114502s\n",
            "Epoch: 43, loss: 0.9177912871042887, time: 1.5937392711639404s\n",
            "Epoch: 44, loss: 0.9129687150319418, time: 1.6164288520812988s\n",
            "Epoch: 45, loss: 0.9619484742482504, time: 2.3301661014556885s\n",
            "Valid at epoch 45\n",
            "   GNN F1-binary-1: 0.7520\tF1-binary-0: 0.9786\tF1-macro: 0.8653\tG-Mean: 0.9150\tAUC: 0.9648\tREC: 0.9164\n",
            "   GNN TP: 141\tTN: 2131\tFN: 22\tFP: 71\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8669\tAP: 0.6339\n",
            "   GNN F1-binary-1: 0.6732\tF1-binary-0: 0.9697\tF1-macro: 0.8215\tG-Mean: 0.8896\tAUC: 0.9574\tREC: 0.8917\n",
            "   GNN TP: 274\tTN: 4262\tFN: 56\tFP: 210\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8390\tAP: 0.6196\n",
            "Epoch: 46, loss: 0.8406885464986166, time: 1.6311166286468506s\n",
            "Epoch: 47, loss: 0.897288958231608, time: 2.25319242477417s\n",
            "Epoch: 48, loss: 0.9499634106953939, time: 1.6427323818206787s\n",
            "Epoch: 49, loss: 0.9084070523579916, time: 1.591254472732544s\n",
            "Epoch: 50, loss: 0.8399585882822672, time: 1.6193978786468506s\n",
            "Valid at epoch 50\n",
            "   GNN F1-binary-1: 0.7236\tF1-binary-0: 0.9746\tF1-macro: 0.8491\tG-Mean: 0.9203\tAUC: 0.9667\tREC: 0.9211\n",
            "   GNN TP: 144\tTN: 2111\tFN: 19\tFP: 91\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8772\tAP: 0.6991\n",
            "   GNN F1-binary-1: 0.6635\tF1-binary-0: 0.9680\tF1-macro: 0.8157\tG-Mean: 0.8925\tAUC: 0.9612\tREC: 0.8942\n",
            "   GNN TP: 277\tTN: 4244\tFN: 53\tFP: 228\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8476\tAP: 0.6946\n",
            "Epoch: 51, loss: 0.850228468577067, time: 1.651268720626831s\n",
            "Epoch: 52, loss: 0.923553466796875, time: 1.6278769969940186s\n",
            "Epoch: 53, loss: 0.9654592672983805, time: 1.621570110321045s\n",
            "Epoch: 54, loss: 0.8820944627126058, time: 1.511927604675293s\n",
            "Epoch: 55, loss: 0.895362377166748, time: 1.644097089767456s\n",
            "Valid at epoch 55\n",
            "   GNN F1-binary-1: 0.6905\tF1-binary-0: 0.9698\tF1-macro: 0.8302\tG-Mean: 0.9189\tAUC: 0.9683\tREC: 0.9194\n",
            "   GNN TP: 145\tTN: 2090\tFN: 18\tFP: 112\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8826\tAP: 0.7313\n",
            "   GNN F1-binary-1: 0.6455\tF1-binary-0: 0.9642\tF1-macro: 0.8048\tG-Mean: 0.8997\tAUC: 0.9629\tREC: 0.9006\n",
            "   GNN TP: 284\tTN: 4206\tFN: 46\tFP: 266\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8523\tAP: 0.7288\n",
            "Epoch: 56, loss: 0.919891357421875, time: 1.5680599212646484s\n",
            "Epoch: 57, loss: 0.8763433297475179, time: 1.6144192218780518s\n",
            "Epoch: 58, loss: 0.8844900925954183, time: 1.581735610961914s\n",
            "Epoch: 59, loss: 0.8422044118245443, time: 1.6149382591247559s\n",
            "Epoch: 60, loss: 0.8751101493835449, time: 1.6148064136505127s\n",
            "Valid at epoch 60\n",
            "   GNN F1-binary-1: 0.7566\tF1-binary-0: 0.9789\tF1-macro: 0.8677\tG-Mean: 0.9212\tAUC: 0.9699\tREC: 0.9223\n",
            "   GNN TP: 143\tTN: 2130\tFN: 20\tFP: 72\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8857\tAP: 0.7498\n",
            "   GNN F1-binary-1: 0.7059\tF1-binary-0: 0.9739\tF1-macro: 0.8399\tG-Mean: 0.8964\tAUC: 0.9658\tREC: 0.8985\n",
            "   GNN TP: 276\tTN: 4296\tFN: 54\tFP: 176\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8552\tAP: 0.7461\n",
            "\tF1-macro: 0.8399\tAUC: 0.9658\tREC: 0.8985\n",
            "  Saving model ...\n",
            "Epoch: 61, loss: 0.8758286635080973, time: 1.629903793334961s\n",
            "Epoch: 62, loss: 0.8379717667897543, time: 1.5837674140930176s\n",
            "Epoch: 63, loss: 0.83761199315389, time: 1.5795185565948486s\n",
            "Epoch: 64, loss: 0.8304382960001627, time: 1.5473144054412842s\n",
            "Epoch: 65, loss: 0.8817715644836426, time: 1.6005280017852783s\n",
            "Valid at epoch 65\n",
            "   GNN F1-binary-1: 0.7559\tF1-binary-0: 0.9786\tF1-macro: 0.8673\tG-Mean: 0.9240\tAUC: 0.9688\tREC: 0.9249\n",
            "   GNN TP: 144\tTN: 2128\tFN: 19\tFP: 74\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8884\tAP: 0.7665\n",
            "   GNN F1-binary-1: 0.6976\tF1-binary-0: 0.9726\tF1-macro: 0.8351\tG-Mean: 0.8982\tAUC: 0.9645\tREC: 0.9001\n",
            "   GNN TP: 278\tTN: 4283\tFN: 52\tFP: 189\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8575\tAP: 0.7581\n",
            "Epoch: 66, loss: 0.8867975076039633, time: 1.5916969776153564s\n",
            "Epoch: 67, loss: 0.8615909417470297, time: 1.597869634628296s\n",
            "Epoch: 68, loss: 0.8973614374796549, time: 1.6006948947906494s\n",
            "Epoch: 69, loss: 0.8755393028259277, time: 1.6355586051940918s\n",
            "Epoch: 70, loss: 0.8907632827758789, time: 2.26904034614563s\n",
            "Valid at epoch 70\n",
            "   GNN F1-binary-1: 0.7784\tF1-binary-0: 0.9812\tF1-macro: 0.8798\tG-Mean: 0.9264\tAUC: 0.9729\tREC: 0.9274\n",
            "   GNN TP: 144\tTN: 2139\tFN: 19\tFP: 63\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8901\tAP: 0.7768\n",
            "   GNN F1-binary-1: 0.7277\tF1-binary-0: 0.9761\tF1-macro: 0.8519\tG-Mean: 0.9074\tAUC: 0.9700\tREC: 0.9090\n",
            "   GNN TP: 282\tTN: 4309\tFN: 48\tFP: 163\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8592\tAP: 0.7670\n",
            "\tF1-macro: 0.8519\tAUC: 0.9700\tREC: 0.9090\n",
            "  Saving model ...\n",
            "Epoch: 71, loss: 0.8410067558288574, time: 1.5861001014709473s\n",
            "Epoch: 72, loss: 0.7667970657348633, time: 1.5385258197784424s\n",
            "Epoch: 73, loss: 0.789148728052775, time: 1.6201653480529785s\n",
            "Epoch: 74, loss: 0.8930133978525797, time: 2.338176965713501s\n",
            "Epoch: 75, loss: 0.8583360513051351, time: 1.646186113357544s\n",
            "Valid at epoch 75\n",
            "   GNN F1-binary-1: 0.7592\tF1-binary-0: 0.9788\tF1-macro: 0.8690\tG-Mean: 0.9272\tAUC: 0.9707\tREC: 0.9280\n",
            "   GNN TP: 145\tTN: 2128\tFN: 18\tFP: 74\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8914\tAP: 0.7857\n",
            "   GNN F1-binary-1: 0.7085\tF1-binary-0: 0.9737\tF1-macro: 0.8411\tG-Mean: 0.9052\tAUC: 0.9674\tREC: 0.9067\n",
            "   GNN TP: 282\tTN: 4288\tFN: 48\tFP: 184\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8603\tAP: 0.7730\n",
            "Epoch: 76, loss: 0.8377525806427002, time: 2.273923873901367s\n",
            "Epoch: 77, loss: 0.8908527692159017, time: 1.6068949699401855s\n",
            "Epoch: 78, loss: 0.8360873063405355, time: 1.5943045616149902s\n",
            "Epoch: 79, loss: 0.864279588063558, time: 1.6179461479187012s\n",
            "Epoch: 80, loss: 0.8593811194101969, time: 1.5856220722198486s\n",
            "Valid at epoch 80\n",
            "   GNN F1-binary-1: 0.7826\tF1-binary-0: 0.9817\tF1-macro: 0.8821\tG-Mean: 0.9268\tAUC: 0.9702\tREC: 0.9279\n",
            "   GNN TP: 144\tTN: 2141\tFN: 19\tFP: 61\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8921\tAP: 0.7908\n",
            "   GNN F1-binary-1: 0.7196\tF1-binary-0: 0.9752\tF1-macro: 0.8474\tG-Mean: 0.9051\tAUC: 0.9672\tREC: 0.9068\n",
            "   GNN TP: 281\tTN: 4302\tFN: 49\tFP: 170\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8611\tAP: 0.7765\n",
            "\tF1-macro: 0.8474\tAUC: 0.9672\tREC: 0.9068\n",
            "  Saving model ...\n",
            "Epoch: 81, loss: 0.7865557670593262, time: 1.678361415863037s\n",
            "Epoch: 82, loss: 0.8355530103047689, time: 1.561194658279419s\n",
            "Epoch: 83, loss: 0.8434898853302002, time: 1.5312559604644775s\n",
            "Epoch: 84, loss: 0.8540111382802328, time: 1.6421301364898682s\n",
            "Epoch: 85, loss: 0.7771369616190592, time: 1.6158311367034912s\n",
            "Valid at epoch 85\n",
            "   GNN F1-binary-1: 0.7527\tF1-binary-0: 0.9789\tF1-macro: 0.8658\tG-Mean: 0.9121\tAUC: 0.9730\tREC: 0.9138\n",
            "   GNN TP: 140\tTN: 2133\tFN: 23\tFP: 69\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8926\tAP: 0.7942\n",
            "   GNN F1-binary-1: 0.7254\tF1-binary-0: 0.9760\tF1-macro: 0.8507\tG-Mean: 0.9043\tAUC: 0.9714\tREC: 0.9061\n",
            "   GNN TP: 280\tTN: 4310\tFN: 50\tFP: 162\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8617\tAP: 0.7791\n",
            "Epoch: 86, loss: 0.8048586845397949, time: 1.6133167743682861s\n",
            "Epoch: 87, loss: 0.7801824410756429, time: 1.6058030128479004s\n",
            "Epoch: 88, loss: 0.8084792296091715, time: 1.6049165725708008s\n",
            "Epoch: 89, loss: 0.853219191233317, time: 1.6073627471923828s\n",
            "Epoch: 90, loss: 0.8021832307179769, time: 1.5933177471160889s\n",
            "Valid at epoch 90\n",
            "   GNN F1-binary-1: 0.7320\tF1-binary-0: 0.9760\tF1-macro: 0.8540\tG-Mean: 0.9156\tAUC: 0.9704\tREC: 0.9167\n",
            "   GNN TP: 142\tTN: 2119\tFN: 21\tFP: 83\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8930\tAP: 0.7972\n",
            "   GNN F1-binary-1: 0.7111\tF1-binary-0: 0.9739\tF1-macro: 0.8425\tG-Mean: 0.9069\tAUC: 0.9662\tREC: 0.9083\n",
            "   GNN TP: 283\tTN: 4289\tFN: 47\tFP: 183\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8622\tAP: 0.7815\n",
            "Epoch: 91, loss: 0.8544165293375651, time: 1.6111063957214355s\n",
            "Epoch: 92, loss: 0.8191626071929932, time: 1.5858333110809326s\n",
            "Epoch: 93, loss: 0.7705932458241781, time: 1.6472601890563965s\n",
            "Epoch: 94, loss: 0.7225754261016846, time: 1.6326735019683838s\n",
            "Epoch: 95, loss: 0.77298370997111, time: 1.57857084274292s\n",
            "Valid at epoch 95\n",
            "   GNN F1-binary-1: 0.7874\tF1-binary-0: 0.9831\tF1-macro: 0.8852\tG-Mean: 0.9067\tAUC: 0.9691\tREC: 0.9093\n",
            "   GNN TP: 137\tTN: 2154\tFN: 26\tFP: 48\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9313\tRecall: 0.5000\tAUC: 0.8935\tAP: 0.7995\n",
            "   GNN F1-binary-1: 0.7623\tF1-binary-0: 0.9810\tF1-macro: 0.8717\tG-Mean: 0.8950\tAUC: 0.9678\tREC: 0.8983\n",
            "   GNN TP: 271\tTN: 4362\tFN: 59\tFP: 110\n",
            "Label1 F1: 0.4822\tAccuracy: 0.9312\tRecall: 0.5000\tAUC: 0.8627\tAP: 0.7836\n",
            "\tF1-macro: 0.8717\tAUC: 0.9678\tREC: 0.8983\n",
            "  Saving model ...\n",
            "Epoch: 96, loss: 0.8308136463165283, time: 2.2630507946014404s\n",
            "Epoch: 97, loss: 0.7828311920166016, time: 1.5712659358978271s\n",
            "Epoch: 98, loss: 0.7833483219146729, time: 1.6295666694641113s\n",
            "Epoch: 99, loss: 0.7602364222208658, time: 1.6128675937652588s\n",
            "Restore model from epoch 95\n",
            "Model path: ./pytorch_models/2023-01-13 16-16-16/amazon_PCGNN.pkl\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 149, in <module>\n",
            "    main(config)\n",
            "  File \"main.py\", line 25, in main\n",
            "    f1_mac_test, f1_1_test, f1_0_test, auc_test, gmean_test, rec_test = model.train()\n",
            "  File \"/content/drive/MyDrive/PC-GNN-main/PC-GNN-main/src/model_handler.py\", line 189, in train\n",
            "    gnn_model.load_state_dict(torch.load(path_saver))\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 771, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 270, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.8/dist-packages/torch/serialization.py\", line 251, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: './pytorch_models/2023-01-13 16-16-16/amazon_PCGNN.pkl'\n"
          ]
        }
      ],
      "source": [
        "!python main.py --config ./config/pcgnn_amazon.yml"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}